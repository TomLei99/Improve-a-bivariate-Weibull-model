{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopy as geopy\n",
    "from scipy.special import gamma\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "import math as math\n",
    "from math import gamma\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translate Stadium to latitude and longitude to calculate the distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /opt/anaconda3/lib/python3.9/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/anaconda3/lib/python3.9/site-packages (from geopy) (2.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import requests\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def get_coordinates(stadium_name):\n",
    "    api_key = \"AIzaSyCFVZQiqRj_z6MGgCDjEK6imywq6rQj8yk\"\n",
    "    url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={stadium_name}&key={api_key}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data[\"status\"] == \"OK\":\n",
    "        # Extracting the latitude and longitude coordinates\n",
    "        latitude = data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        longitude = data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        return (latitude, longitude)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculate_distance(home_stadium_name, away_stadium_name):\n",
    "    # Getting the coordinates of the home stadium\n",
    "    home_coordinates = get_coordinates(home_stadium_name)\n",
    "    if home_coordinates is None:\n",
    "        print(f\"Unable to find coordinates for {home_stadium_name}.\")\n",
    "        return None\n",
    "\n",
    "    # Getting the coordinates of the away stadium\n",
    "    away_coordinates = get_coordinates(away_stadium_name)\n",
    "    if away_coordinates is None:\n",
    "        print(f\"Unable to find coordinates for {away_stadium_name}.\")\n",
    "        return None\n",
    "\n",
    "    # Calculating the distance using the Haversine formula\n",
    "    distance = geodesic(home_coordinates, away_coordinates).miles\n",
    "\n",
    "    return distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between West Bromwich Albion Stadium Megastore and Turf Moor Stadium is approximately 89.17 miles.\n"
     ]
    }
   ],
   "source": [
    "#Test code\n",
    "home_stadium_name = \"West Bromwich Albion Stadium Megastore\"\n",
    "away_stadium_name = \"Turf Moor Stadium\"\n",
    "\n",
    "distance = calculate_distance(home_stadium_name, away_stadium_name)\n",
    "if distance is not None:\n",
    "    print(f\"The distance between {home_stadium_name} and {away_stadium_name} is approximately {distance:.2f} miles.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's import Dataset and preprocessing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('E0-2022.csv')\n",
    "\n",
    "df[\"Date\"] = df[\"Date\"].str.split(\"/\").str[::-1].apply(\"/\".join)\n",
    "df.sort_values(by=\"Date\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[\"fixture\"] = df.index // 10\n",
    "\n",
    "df[\"HomeStadium\"] = df[\"HomeTeam\"].replace({\n",
    "    'Crystal Palace' : 'Selhurst Park',\n",
    "    'Fulham': 'Craven Cottage',\n",
    "    'Bournemouth': 'Vitality Stadium',\n",
    "    'Leeds': 'Elland Road',\n",
    "    'Newcastle': \"St. James's Park\",\n",
    "    'Tottenham': 'Tottenham Hotspur Stadium',\n",
    "    'Everton': 'Goodison Park',\n",
    "    'Leicester': 'King Power Stadium',\n",
    "    'Man United': 'Old Trafford',\n",
    "    'West Ham': 'London Stadium',\n",
    "    'Brentford': 'Gtech Community Stadium',\n",
    "    'Wolves': 'Molineux Stadium',\n",
    "    'Southampton': \"St. Mary's Stadium\",\n",
    "    'Arsenal': 'Emirates Stadium',\n",
    "    'Brighton': 'Amex Stadium',\n",
    "    'Aston Villa': 'Villa Park Reception',\n",
    "    'Man City': 'Etihad Stadium',\n",
    "    \"Nott'm Forest\": 'The Bridgford Stand',\n",
    "    'Chelsea': 'Stamford Bridge',\n",
    "    'Liverpool': 'Anfield',\n",
    "    \"Sheffield United\": \"Sheffield United Football Club Ticket Office\",\n",
    "    \"West Brom\":\"West Bromwich Albion Stadium Megastore\",\n",
    "    \"Cardiff\": \"Cardiff City Stadium\",\n",
    "    \"Norwich\": \"Carrow Road Stadium\",\n",
    "    \"Huddersfield\": \"Galpharm Stadium\",\n",
    "    \"Watford\":\"Vicarage Road Stadium\",\n",
    "    \"Burnley\": \"Turf Moor Stadium\",\n",
    "    \"Stoke\": \"bet365 Stadium\"\n",
    "})\n",
    "\n",
    "df[\"AwayStadium\"] = df[\"AwayTeam\"].replace({\n",
    "    'Crystal Palace' : 'Selhurst Park',\n",
    "    'Fulham': 'Craven Cottage',\n",
    "    'Bournemouth': 'Vitality Stadium',\n",
    "    'Leeds': 'Elland Road',\n",
    "    'Newcastle': \"St. James's Park\",\n",
    "    'Tottenham': 'Tottenham Hotspur Stadium',\n",
    "    'Everton': 'Goodison Park',\n",
    "    'Leicester': 'King Power Stadium',\n",
    "    'Man United': 'Old Trafford',\n",
    "    'West Ham': 'London Stadium',\n",
    "    'Brentford': 'Gtech Community Stadium',\n",
    "    'Wolves': 'Molineux Stadium',\n",
    "    'Southampton': \"St. Mary's Stadium\",\n",
    "    'Arsenal': 'Emirates Stadium',\n",
    "    'Brighton': 'Amex Stadium',\n",
    "    'Aston Villa': 'Villa Park Reception',\n",
    "    'Man City': 'Etihad Stadium',\n",
    "    \"Nott'm Forest\": 'The Bridgford Stand',\n",
    "    'Chelsea': 'Stamford Bridge',\n",
    "    'Liverpool': 'Anfield',\n",
    "    \"Sheffield United\": \"Sheffield United Football Club Ticket Office\",\n",
    "    \"West Brom\": \"West Bromwich Albion Stadium Megastore\",\n",
    "    \"Cardiff\": \"Cardiff City Stadium\",\n",
    "    \"Norwich\": \"Carrow Road Stadium\",\n",
    "    \"Huddersfield\": \"Galpharm Stadium\",\n",
    "    \"Watford\":\"Vicarage Road Stadium\",\n",
    "    \"Burnley\": \"Turf Moor Stadium\",\n",
    "    \"Stoke\": \"bet365 Stadium\"\n",
    "})\n",
    "\n",
    "df[\"Distance\"] = df.apply(lambda row: calculate_distance(row[\"HomeStadium\"], row[\"AwayStadium\"]), axis=1)\n",
    "df[\"Distance_factor\"] = df[\"Distance\"]/df[\"Distance\"].mean()\n",
    "\n",
    "\n",
    "df['Time_num'] = (df['Time'].str.replace(':', '')).astype(int)\n",
    "\n",
    "df_new = df[[\"fixture\", \"Time\",\"Date\", \"HomeTeam\",\"AwayTeam\", \"FTHG\", \"FTAG\"]].copy()\n",
    "\n",
    "df = df[[\"fixture\", \"Date\",\"Time_num\", \"HomeTeam\",\"HomeStadium\",\"AwayTeam\",\"AwayStadium\", \"FTHG\", \"FTAG\",\"Distance\", \"Distance_factor\",\"B365C>2.5\",\"B365C<2.5\"]].copy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(df[\"Distance_factor\"], density=True, bins=20, edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Distance Factor')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Distance Factor')\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get teams names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def get_all_teams(df: pd.DataFrame) -> List:\n",
    "    df = df.copy()\n",
    "\n",
    "    all_teams = list(set(list(df[\"HomeTeam\"].unique()) + list(df[\"AwayTeam\"].unique())))\n",
    "\n",
    "    return all_teams\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the parameters from the original paper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coefficient = {\n",
    "'KAPPA': -0.4561,\n",
    "'C1': 1.050,\n",
    "'C2': 0.9831,\n",
    "'GAMMA': 0.2958,\n",
    "'XI': 0.002,\n",
    "'GOAL_RANGE': range(5)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import a Bivariate Weibull Model Step by Step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache(maxsize=None)  ## It is a technique to cache the results of function calls and avoid redundant computations\n",
    "\n",
    "def Alph_j(x: int, j: int, c: float) -> float:\n",
    "    if x == 0:\n",
    "        return gamma(c * j + 1) / gamma(j + 1)\n",
    "    elif j < x:\n",
    "        raise ValueError(f\"{x, j}\")\n",
    "    else:\n",
    "        return sum(\n",
    "            [\n",
    "                Alph_j(x - 1, m, c) * gamma(c * j - c * m + 1) / gamma(j - m + 1)\n",
    "                for m in range(x - 1, j)\n",
    "            ]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate the Weibull Count distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weibull_first_layer(x: int, c: float, l: float, t: float = 1, j: int = 0) -> float:\n",
    "    return (-1) ** (x + j) * (l * t**c) ** j * Alph_j(x, j, c) / gamma(c * j + 1)\n",
    "\n",
    "\n",
    "##cumulative formula\n",
    "def weibull(x: int, c: float, l: float, t: float = 1) -> float:\n",
    "    return sum(\n",
    "        [weibull_first_layer(x, c, l, t, j) for j in range(x, x + 50)]\n",
    "    )  # 50 terms is an approximation of inf, but apparently good enough\n",
    "\n",
    "def c_weibull(x: int, c: float, l: float, t: float = 1) -> float:\n",
    "    return sum([weibull(i, c, l, t) for i in range(0, x + 1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using a Frank Copula to generate a bivariate model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def frank_copula(u: float, v: float, k: float = coefficient['KAPPA']) -> float:\n",
    "    return -1/ k * np.log(1 + (np.exp(-k * u) - 1) * (np.exp(-k * v) - 1) / (np.exp(-k) - 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate The log-likelihood"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def w_loglikelihood(\n",
    "    y1: int, y2: int, l1: float, l2: float, c1=coefficient['C1'], c2=coefficient['C2']\n",
    ") -> float:\n",
    "    x1 = c_weibull(y1, c1, l1)\n",
    "    x2 = c_weibull(y2, c2, l2)\n",
    "    x3 = c_weibull(y1 - 1, c1, l1)\n",
    "    x4 = c_weibull(y2 - 1, c2, l2)\n",
    "\n",
    "    return (\n",
    "        frank_copula(x1, x2) - frank_copula(x1, x4) - frank_copula(x3, x2) + frank_copula(x3, x4)\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build the Bivariate Weibull Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BivariateWeibullModel:\n",
    "    def __init__(self): # This is a parameter choose by Georgi in his paper\n",
    "        self.gamma = coefficient['GAMMA']\n",
    "\n",
    "    def _get_all_teams(self, df: pd.DataFrame):\n",
    "        self.teams = get_all_teams(df) ## To get all team's name\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _get_lambda(self, a: float, b: float, home: bool): ##to calculate the team strenghth parameter Lambda\n",
    "        _lambda = a + b\n",
    "        if home:\n",
    "            _lambda += self.gamma\n",
    "        return np.exp(_lambda)\n",
    "\n",
    "    @property\n",
    "    def mapping_team(self):\n",
    "        return {team: n for n, team in enumerate(self.teams)}\n",
    "\n",
    "    @property\n",
    "    def inverse_team(self):\n",
    "        return {v: k for k, v in self.mapping_team.items()}  ##To record the alpha and beta coefficient of each team more convenient\n",
    "\n",
    "    @property\n",
    "    def team_strength(self):\n",
    "        X = pd.DataFrame(self.C, columns=[\"alpha\", \"beta\"])\n",
    "        X.reset_index(inplace=True)\n",
    "        X.rename(columns={\"index\": \"team\"}, inplace=True)\n",
    "        X[\"team\"] = X[\"team\"].map(self.inverse_team)\n",
    "        return X\n",
    "\n",
    "#Overall, this code initializes the attribute `C` of the instance with a 2-dimensional array of random numbers sampled from a normal distribution, scaled down by a factor of 0.1.\n",
    "    def _initialise_coefficients(self):\n",
    "        self.C = 0.1 * (np.random.normal(0, 1, (len(self.teams), 2)))\n",
    "\n",
    "    def log_likelihood(self, df: pd.DataFrame, C: np.array) -> float:\n",
    "        log_l = 0\n",
    "\n",
    "        max_fixture = df[\"fixture\"].max()\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            home = row[\"HomeTeam\"]\n",
    "            away = row[\"AwayTeam\"]\n",
    "            distance = row[\"Distance\"]\n",
    "\n",
    "            distance_factor = row[\"Distance_factor\"]\n",
    "            time_factor = row[\"Time_num\"]\n",
    "\n",
    "            i, j = self.mapping_team[home], self.mapping_team[away]\n",
    "            l1 = self._get_lambda(C[i][0], C[j][1],  home=True)  + distance_factor/20  #+ distance*math.exp(-distance * 3)\n",
    "            l2 = self._get_lambda(C[j][0], C[i][1],  home=False)\n",
    "\n",
    "\n",
    "            log_l += np.log(\n",
    "                np.exp(-coefficient['XI'] * (max_fixture - row[\"fixture\"]))\n",
    "                * w_loglikelihood(y1=row[\"FTHG\"], y2=row[\"FTAG\"], l1=l1, l2=l2)\n",
    "            )\n",
    "\n",
    "        return log_l\n",
    "\n",
    "    def _get_gradients(self, df: pd.DataFrame, C: np.array):  #  To calculates the gradients of a log-likelihood\n",
    "        C = C.copy()\n",
    "        df = df.copy()\n",
    "        eps = 1e-6\n",
    "\n",
    "        gradients = np.zeros_like(C)\n",
    "\n",
    "        for i in range(C.shape[0]):\n",
    "            for j in range(C.shape[1]):\n",
    "                C_plus = C.copy()\n",
    "                C_minus = C.copy()\n",
    "                C_plus[i, j] += eps\n",
    "                C_minus[i, j] -= eps\n",
    "                gradients[i, j] = (\n",
    "                    self.log_likelihood(df, C_plus) - self.log_likelihood(df, C_minus) ) / (2 * eps)\n",
    "\n",
    "        return gradients\n",
    "\n",
    "    import time\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        train: pd.DataFrame,\n",
    "        n_iter: int = 50,\n",
    "        learning_rate: float = 0.001,\n",
    "        verbose: bool = True,\n",
    "        test: pd.DataFrame = None,\n",
    "    ):\n",
    "        train = train.copy()\n",
    "        self._get_all_teams(train)\n",
    "        self._initialise_coefficients()\n",
    "\n",
    "        train_log_likelihood = self.log_likelihood(train, self.C)\n",
    "        if test is not None:\n",
    "            test_log_likelihood = self.log_likelihood(test, self.C)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Starting train likelihood: {train_log_likelihood}\")\n",
    "            if test is not None:\n",
    "                print(f\"Starting test likelihood: {test_log_likelihood}\")\n",
    "\n",
    "        self.train_likelihoods = [train_log_likelihood]\n",
    "        if test is not None:\n",
    "            self.test_likelihoods = [test_log_likelihood]\n",
    "\n",
    "        C = self.C.copy()\n",
    "        for n in range(n_iter):\n",
    "            C += learning_rate * self._get_gradients(train, C)\n",
    "            self.C = C.copy()\n",
    "            train_log_likelihood = self.log_likelihood(train, self.C)\n",
    "            self.train_likelihoods.append(train_log_likelihood)\n",
    "            if test is not None:\n",
    "                test_log_likelihood = self.log_likelihood(test, self.C)\n",
    "                self.test_likelihoods.append(test_log_likelihood)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Step {n + 1}, current likelihood: {train_log_likelihood}\")\n",
    "                if test is not None:\n",
    "                    print(f\"Step {n + 1}, current test likelihood: {test_log_likelihood}\")\n",
    "\n",
    "            if self.train_likelihoods[-1] - self.train_likelihoods[-2] < 10e-4:\n",
    "                print(\"Algorithm has converged, we can stop our fitting here\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    def predict_all_scores(self, home: str, away: str):\n",
    "        results = []\n",
    "\n",
    "        C = self.team_strength.set_index(\"team\").to_dict(orient=\"index\")\n",
    "        for i in coefficient['GOAL_RANGE']:\n",
    "            for j in coefficient['GOAL_RANGE']:\n",
    "                l1 = self._get_lambda(\n",
    "                    C[home][\"alpha\"], C[away][\"beta\"], home=True\n",
    "                )\n",
    "                l2 = self._get_lambda(\n",
    "                    C[home][\"beta\"], C[away][\"alpha\"], home=False\n",
    "                )\n",
    "                p = w_loglikelihood(i, j, l1, l2)\n",
    "                results.append([i, j, p])\n",
    "\n",
    "        X = pd.DataFrame(results, columns=[\"H\", \"A\", \"p\"])\n",
    "\n",
    "        return X\n",
    "\n",
    "    def predict_under_over_by_matches(self, home: str, away: str):\n",
    "        X = self.predict_all_scores(home, away)\n",
    "\n",
    "        X[\"over\"] = X[\"H\"] + X[\"A\"] > 2.5\n",
    "\n",
    "        under = X[~X[\"over\"]][\"p\"].sum()\n",
    "        over = 1 - under\n",
    "\n",
    "        return (under, over)\n",
    "\n",
    "\n",
    "    def predict_under_and_over(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "\n",
    "        pred = df.apply(\n",
    "            lambda row: self.predict_under_over_by_matches(\n",
    "                row[\"HomeTeam\"],\n",
    "                row[\"AwayTeam\"],\n",
    "            ),\n",
    "            axis=1,\n",
    "        ).apply(pd.Series)\n",
    "\n",
    "        pred.rename(columns={0: \"under\", 1: \"over\"}, inplace=True)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def predict_result_by_matches(self, home: str, away: str):\n",
    "        X = self.predict_all_scores(home, away)\n",
    "\n",
    "        X[\"pred\"] = \"0\"\n",
    "        X.loc[X[\"H\"] > X[\"A\"], \"pred\"] = \"1\"\n",
    "        X.loc[X[\"H\"] < X[\"A\"], \"pred\"] = \"2\"\n",
    "        X.loc[X[\"H\"] == X[\"A\"], \"pred\"] = \"X\"\n",
    "\n",
    "        scores = X.groupby(\"pred\")[\"p\"].sum()\n",
    "        scores /= (\n",
    "            scores.sum()\n",
    "        )\n",
    "\n",
    "        return scores.T\n",
    "\n",
    "    def predict_1x2_goals(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "\n",
    "        pred = df.apply(\n",
    "            lambda row: self.predict_result_by_matches(\n",
    "                row[\"HomeTeam\"],\n",
    "                row[\"AwayTeam\"],\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def get_results(self):\n",
    "        return pd.DataFrame(self.C).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now Let's Begin with the simpler Poisson distribution-based model\n",
    "### 1.See the difference in Match Begin Time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('Data_Score.csv')\n",
    "data_noon = data[(data[\"Time\"] == \"12:00\") | (data[\"Time\"] == \"12:30\") | (data[\"Time\"] == \"13:00\") | (data[\"Time\"] == \"13:30\") | (data[\"Time\"] == \"14:00\") | (data[\"Time\"] == \"14:05\") | (data[\"Time\"] == \"14:15\")]\n",
    "\n",
    "data_afternoon = data[(data[\"Time\"] == \"15:00\") | (data[\"Time\"] == \"16:30\") | (data[\"Time\"] == \"16:00\") | (data[\"Time\"] == \"17:00\") | (data[\"Time\"] == \"17:30\") | (data[\"Time\"] == \"17:45\")| (data[\"Time\"] == \"18:00\")]\n",
    "\n",
    "data_night = data[(data[\"Time\"] == \"19:00\") | (data[\"Time\"] == \"19:15\") | (data[\"Time\"] == \"19:30\") | (data[\"Time\"] == \"19:45\") | (data[\"Time\"] == \"20:00\") | (data[\"Time\"] == \"20:15\")]\n",
    "\n",
    "data_avg = data[data[\"Time\"] != \"00:00\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the average number of goals scored by the home team\n",
    "avg_home_goals_noon = data_noon['FTHG'].mean()\n",
    "\n",
    "# Calculate the average number of goals scored by the away team\n",
    "avg_away_goals_noon = data_noon['FTAG'].mean()\n",
    "\n",
    "# Create a Poisson distribution for the home team goals\n",
    "home_goals_dist_noon = poisson(avg_home_goals_noon)\n",
    "\n",
    "# Create a Poisson distribution for the away team goals\n",
    "away_goals_dist_noon = poisson(avg_away_goals_noon)\n",
    "\n",
    "# Generate a list of possible goal counts (0 to 10, for example)\n",
    "goal_counts = list(range(7))\n",
    "\n",
    "# Calculate the probabilities for each goal count for the home team\n",
    "home_probs_noon = home_goals_dist_noon.pmf(goal_counts)\n",
    "\n",
    "# Calculate the probabilities for each goal count for the away team\n",
    "away_probs_noon = away_goals_dist_noon.pmf(goal_counts)\n",
    "\n",
    "\n",
    "#At afternoon\n",
    "avg_home_goals_afternoon = data_afternoon['FTHG'].mean()\n",
    "avg_away_goals_afternoon = data_afternoon['FTAG'].mean()\n",
    "\n",
    "home_goals_dist_af = poisson(avg_home_goals_afternoon)\n",
    "away_goals_dist_af = poisson(avg_away_goals_afternoon)\n",
    "\n",
    "home_probs_af = home_goals_dist_af.pmf(goal_counts)\n",
    "away_probs_af = away_goals_dist_af.pmf(goal_counts)\n",
    "\n",
    "#At night\n",
    "avg_home_goals_night = data_night['FTHG'].mean()\n",
    "avg_away_goals_night = data_night['FTAG'].mean()\n",
    "\n",
    "home_goals_dist_night = poisson(avg_home_goals_night)\n",
    "away_goals_dist_night = poisson(avg_away_goals_night)\n",
    "\n",
    "home_probs_night = home_goals_dist_night.pmf(goal_counts)\n",
    "away_probs_night = away_goals_dist_night.pmf(goal_counts)\n",
    "\n",
    "#Average\n",
    "avg_home_goals = data['FTHG'].mean()\n",
    "avg_away_goals = data['FTAG'].mean()\n",
    "\n",
    "home_goals_dist = poisson(avg_home_goals)\n",
    "away_goals_dist = poisson(avg_away_goals)\n",
    "\n",
    "home_probs = home_goals_dist.pmf(goal_counts)\n",
    "away_probs = away_goals_dist.pmf(goal_counts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the width of each bar\n",
    "bar_width = 0.2\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "positions = np.arange(len(goal_counts))\n",
    "\n",
    "# Plot the bar plots\n",
    "plt.bar(positions - bar_width, home_probs_noon, width=bar_width, label='Home Team at noon')\n",
    "plt.bar(positions, home_probs_af, width=bar_width, label='Home Team afternoon')\n",
    "plt.bar(positions + bar_width, home_probs_night, width=bar_width, label='Home Team at night')\n",
    "plt.bar(positions + 2 * bar_width, home_probs, width=bar_width, label='Home Team avg')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Goals')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Poisson Distribution of Goals (Home Team)')\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "plt.xticks(positions, goal_counts)\n",
    "\n",
    "# Adjust the legend position\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bar_width = 0.2\n",
    "positions = np.arange(len(goal_counts))\n",
    "\n",
    "plt.bar(positions - bar_width, away_probs_noon, width=bar_width, label='Away Team at noon')\n",
    "plt.bar(positions, away_probs_af, width=bar_width, label='Away Team afternoon')\n",
    "plt.bar(positions + bar_width, away_probs_night, width=bar_width, label='Away Team at night')\n",
    "plt.bar(positions + 2 * bar_width, away_probs, width=bar_width, label='Away Team avg')\n",
    "\n",
    "plt.xlabel('Number of Goals')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Distribution of Goals (Away Team)')\n",
    "plt.xticks(positions, goal_counts)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Weibull distribution and Poisson distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_home = []\n",
    "\n",
    "for i in goal_counts:\n",
    "    l_home = 1.50\n",
    "    c_home = 1.06\n",
    "    p =weibull(i, c_home, l_home, t=1)\n",
    "    results_home.append([i,p])\n",
    "\n",
    "print(results_home)\n",
    "\n",
    "x_home = [result[0] for result in results_home]\n",
    "y_home = [result[1] for result in results_home]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_away = []\n",
    "\n",
    "for i in goal_counts:\n",
    "    l_away = 1.10\n",
    "    c_away = 0.85\n",
    "    p =weibull(i, c_away, l_away, t=1)\n",
    "    results_away.append([i,p])\n",
    "\n",
    "print(results_away)\n",
    "\n",
    "x_away = [result[0] for result in results_away]\n",
    "y_away = [result[1] for result in results_away]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the width of each bar\n",
    "bar_width = 0.15\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "positions = np.arange(len(goal_counts))\n",
    "\n",
    "# Plot the bar plots\n",
    "plt.bar(positions - 2 * bar_width, home_probs_noon, width=bar_width, label='Home Team at noon')\n",
    "plt.bar(positions - bar_width, home_probs_af, width=bar_width, label='Home Team afternoon')\n",
    "plt.bar(positions, home_probs_night, width=bar_width, label='Home Team at night')\n",
    "plt.bar(positions + bar_width, home_probs, width=bar_width, label='Home Team Possion')\n",
    "plt.bar(positions + 2 * bar_width, y_home, width=bar_width, label='Home Team Weibull')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Number of Goals')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Poisson Distribution of Goals (Home Team)')\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "plt.xticks(positions, goal_counts)\n",
    "\n",
    "# Adjust the legend position\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "bar_width = 0.15\n",
    "positions = np.arange(len(goal_counts))\n",
    "\n",
    "plt.bar(positions - 2 * bar_width, away_probs_noon, width=bar_width, label='Away Team at noon')\n",
    "plt.bar(positions - bar_width, away_probs_af, width=bar_width, label='Away Team afternoon')\n",
    "plt.bar(positions, away_probs_night, width=bar_width, label='Away Team at night')\n",
    "plt.bar(positions + bar_width, away_probs, width=bar_width, label='Away Team Possion')\n",
    "plt.bar(positions + 2 * bar_width, y_away, width=bar_width, label='Away Team Weibull')\n",
    "\n",
    "plt.xlabel('Number of Goals')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Poisson Distribution of Goals (Away Team)')\n",
    "plt.xticks(positions, goal_counts)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(df, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w = BivariateWeibullModel()\n",
    "w.fit(train, learning_rate=0.01,test = test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w.team_strength.sort_values(\"alpha\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w.team_strength.sort_values(\"beta\", ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_test = test.copy()\n",
    "TRAIN = train.join(w.predict_under_and_over(train))\n",
    "TEST = test.join(w.predict_under_and_over(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN[\"over_2.5_true\"] = TRAIN[\"FTHG\"] + TRAIN[\"FTAG\"] > 2.5\n",
    "TRAIN[\"over_pred\"] = (TRAIN[\"over\"] > TRAIN[\"under\"])\n",
    "TRAIN[\"over_bet_pred\"] = (TRAIN[\"B365C>2.5\"] < TRAIN[\"B365C<2.5\"])\n",
    "\n",
    "\n",
    "TEST[\"over_2.5_true\"] = TEST[\"FTHG\"] + TEST[\"FTAG\"] > 2.5\n",
    "TEST[\"over_pred\"] = TEST[\"over\"] > TEST[\"under\"]\n",
    "TEST[\"over_bet_pred\"] = (TEST[\"B365C>2.5\"] < TEST[\"B365C<2.5\"])\n",
    "\n",
    "TRAIN[\"Kelly_fr\"] = TRAIN.apply(lambda row: ((row[\"over\"] * row[\"B365C>2.5\"] - (1-row[\"over\"] )) / row[\"B365C>2.5\"])\n",
    "                                    if row[\"over_pred\"]\n",
    "                                    else ((row[\"under\"] * row[\"B365C<2.5\"] - (1-row[\"under\"] )) / row[\"B365C<2.5\"]),\n",
    "                                    axis=1)\n",
    "\n",
    "TEST[\"Kelly_fr\"] = TEST.apply(lambda row: ((row[\"over\"] * row[\"B365C>2.5\"] - (1-row[\"over\"] )) / row[\"B365C>2.5\"])\n",
    "                                    if row[\"over_pred\"]\n",
    "                                    else ((row[\"under\"] * row[\"B365C<2.5\"] - (1-row[\"under\"] )) / row[\"B365C<2.5\"]),\n",
    "                                    axis=1)\n",
    "\n",
    "TRAIN[\"ROI\"] = TRAIN.apply(lambda row: (row[\"Kelly_fr\"] * (row[\"B365C>2.5\"] - 1))\n",
    "                                     if row[\"over_pred\"] and row[\"over_bet_pred\"]\n",
    "                                     else (row[\"Kelly_fr\"] * (row[\"B365C<2.5\"] - 1))\n",
    "                                     if not row[\"over_pred\"] and not row[\"over_bet_pred\"]\n",
    "                                     else (-row[\"Kelly_fr\"]),\n",
    "                                     axis=1)\n",
    "\n",
    "TEST[\"ROI\"] = TEST.apply(lambda row: (row[\"Kelly_fr\"] * (row[\"B365C>2.5\"] - 1))\n",
    "                                     if row[\"over_pred\"] and row[\"over_bet_pred\"]\n",
    "                                     else (row[\"Kelly_fr\"] * (row[\"B365C<2.5\"] - 1))\n",
    "                                     if not row[\"over_pred\"] and not row[\"over_bet_pred\"]\n",
    "                                     else (-row[\"Kelly_fr\"]),\n",
    "                                     axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_Best = TEST[TEST[[\"under\", \"over\"]].max(axis=1) > 0.7]\n",
    "TRAIN_Best = TRAIN[TRAIN[[\"under\", \"over\"]].max(axis=1) > 0.7]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(TRAIN[\"over_2.5_true\"], TRAIN[\"over_pred\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(TEST[\"over_2.5_true\"], TEST[\"over_pred\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_right = TRAIN[TRAIN[\"over_2.5_true\"] == TRAIN[\"over_pred\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_right"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN[\"ROI\"].mean()*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(TRAIN_right[\"ROI\"]*TRAIN_right[\"Kelly_fr\"]).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN[\"Kelly_fr\"].mean()*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST[\"ROI\"].mean()*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_Best"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_Best[\"ROI\"].mean()*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(TRAIN_Best[\"over_2.5_true\"], TRAIN_Best[\"over_pred\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
